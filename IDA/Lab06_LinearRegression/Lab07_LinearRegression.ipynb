{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY6Srt5R1li0"
      },
      "source": [
        "# Linear Regression\n",
        "\n",
        "In this tutorial we will implement a linear regression model. We will also implement a function that splits the available data into a training and a testing part.\n",
        "\n",
        "## Problem Setting\n",
        "\n",
        "We will use the Boston Housing Dataset. This dataset contains information collected by the U.S Census Service concerning housing in the city of Boston in the state of Massachusetts in 1978. Our goal is to predict the median value of the houses in a particular town in the city of Boston given its attributes. Check the file ’housing_features_description.txt’ for more information on the attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kHxSLZ7w1li1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# for auto-reloading external modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "### NOTE: The boston dataset has an ethical problem. More on this can e.g. be found in the scikit documentation. ###\n",
        "### Summary: The dataset contains the proportion of black people, which was assumed that racial self-segregation had a positive impact on house prices. ###\n",
        "\n",
        "\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "boston_data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "boston_target = raw_df.values[1::2, 2]\n",
        "\n",
        "df=pd.DataFrame(boston_data)\n",
        "df.columns=['crime_rate','res_land_zoned','industry','charles_river','nox','avg_num_rooms','prop_bf_1940','dst_emply_center','rd_highway_idx','tax_rate','stdnt_tchr_ratio','prop_blacks','low_status_pct']\n",
        "X=boston_data\n",
        "y=boston_target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BkyIMHZN1li3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crime_rate</th>\n",
              "      <th>res_land_zoned</th>\n",
              "      <th>industry</th>\n",
              "      <th>charles_river</th>\n",
              "      <th>nox</th>\n",
              "      <th>avg_num_rooms</th>\n",
              "      <th>prop_bf_1940</th>\n",
              "      <th>dst_emply_center</th>\n",
              "      <th>rd_highway_idx</th>\n",
              "      <th>tax_rate</th>\n",
              "      <th>stdnt_tchr_ratio</th>\n",
              "      <th>prop_blacks</th>\n",
              "      <th>low_status_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.02985</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.430</td>\n",
              "      <td>58.7</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.12</td>\n",
              "      <td>5.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.08829</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.012</td>\n",
              "      <td>66.6</td>\n",
              "      <td>5.5605</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>395.60</td>\n",
              "      <td>12.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.14455</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.172</td>\n",
              "      <td>96.1</td>\n",
              "      <td>5.9505</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>396.90</td>\n",
              "      <td>19.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.21124</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>5.631</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.0821</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.63</td>\n",
              "      <td>29.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.17004</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.004</td>\n",
              "      <td>85.9</td>\n",
              "      <td>6.5921</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.71</td>\n",
              "      <td>17.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   crime_rate  res_land_zoned  industry  charles_river    nox  avg_num_rooms  \\\n",
              "0     0.00632            18.0      2.31            0.0  0.538          6.575   \n",
              "1     0.02731             0.0      7.07            0.0  0.469          6.421   \n",
              "2     0.02729             0.0      7.07            0.0  0.469          7.185   \n",
              "3     0.03237             0.0      2.18            0.0  0.458          6.998   \n",
              "4     0.06905             0.0      2.18            0.0  0.458          7.147   \n",
              "5     0.02985             0.0      2.18            0.0  0.458          6.430   \n",
              "6     0.08829            12.5      7.87            0.0  0.524          6.012   \n",
              "7     0.14455            12.5      7.87            0.0  0.524          6.172   \n",
              "8     0.21124            12.5      7.87            0.0  0.524          5.631   \n",
              "9     0.17004            12.5      7.87            0.0  0.524          6.004   \n",
              "\n",
              "   prop_bf_1940  dst_emply_center  rd_highway_idx  tax_rate  stdnt_tchr_ratio  \\\n",
              "0          65.2            4.0900             1.0     296.0              15.3   \n",
              "1          78.9            4.9671             2.0     242.0              17.8   \n",
              "2          61.1            4.9671             2.0     242.0              17.8   \n",
              "3          45.8            6.0622             3.0     222.0              18.7   \n",
              "4          54.2            6.0622             3.0     222.0              18.7   \n",
              "5          58.7            6.0622             3.0     222.0              18.7   \n",
              "6          66.6            5.5605             5.0     311.0              15.2   \n",
              "7          96.1            5.9505             5.0     311.0              15.2   \n",
              "8         100.0            6.0821             5.0     311.0              15.2   \n",
              "9          85.9            6.5921             5.0     311.0              15.2   \n",
              "\n",
              "   prop_blacks  low_status_pct  \n",
              "0       396.90            4.98  \n",
              "1       396.90            9.14  \n",
              "2       392.83            4.03  \n",
              "3       394.63            2.94  \n",
              "4       396.90            5.33  \n",
              "5       394.12            5.21  \n",
              "6       395.60           12.43  \n",
              "7       396.90           19.15  \n",
              "8       386.63           29.93  \n",
              "9       386.71           17.10  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2pPZJYnLNVj"
      },
      "source": [
        "# Note 1:\n",
        "\n",
        "Think about the ethical aspects of this dataset and machine learning in general. \n",
        "\n",
        "Can you always trust your data source? Can we use every possible information for our models?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJG66FPb1li3"
      },
      "source": [
        "### Exercise 1\n",
        "\n",
        "Write the *split_train_test(X,y,split,seed)*, given an instance matrix $X \\in \\mathbb{R}^{N \\times D}$, labels $y \\in Y^N$, a split ratio in $[0, 1]$ and a random seed $\\in \\mathbb{Z}$. Split the dataset in $(split×100)\\%$ of the instances for training our model and the rest for testing, i.e. \n",
        "\n",
        "$$ \\left|X_{\\text{train}}\\right| = \\lceil \\text{split} \\cdot N \\rceil, \\qquad |X_{\\text{train}}| + |X_{\\text{test}}| = N. $$\n",
        "Make sure you use the given random number generator seed so we all get the same results. The function is supposed to return:\n",
        "\n",
        "- X_train, y_train: the training instances and labels;\n",
        "- X_test, y_test: the test instances and labels,\n",
        "\n",
        "in the same order as was mentioned.\n",
        "\n",
        "Hint: It may be helpful to use shuffling functionality (e.g. np.random.shuffle)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eZ2by_fO1li4"
      },
      "outputs": [],
      "source": [
        "def split_train_test(X, y, split, seed):\n",
        "    # return X_train, X_test, y_train, y_test = train_test_split(X_versi, y_versi, test_size=split, random_state=seed)\n",
        "    # Set the random seed for reproducibility\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # Number of instances\n",
        "    N = X.shape[0]\n",
        "    \n",
        "    # Generate a shuffled index array\n",
        "    indices = np.arange(N)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "    # Calculate the split index\n",
        "    split_index = int(np.ceil(split * N))\n",
        "    \n",
        "    # Split the indices into training and testing\n",
        "    train_indices = indices[:split_index]\n",
        "    test_indices = indices[split_index:]\n",
        "    \n",
        "    # Split the data into training and testing sets\n",
        "    X_train = X[train_indices]\n",
        "    y_train = y[train_indices]\n",
        "    X_test = X[test_indices]\n",
        "    y_test = y[test_indices]\n",
        "    \n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxm9S36_1li4"
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "Write the function *train_linear_reg(X_train,y_train,lmbd)*.\n",
        "Implement the ridge regression model (slide 24). The function should output the learned weight vector $\\theta \\in \\mathbb{R}^D$ or $\\mathbb{R}^{D+1}$ (depending on whether you are adding *bias*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3LDp7ssz1li5"
      },
      "outputs": [],
      "source": [
        "def train_linear_reg(X_train, y_train, lmbd):\n",
        "    # Add bias term (column of ones) to X_train\n",
        "    X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "    \n",
        "    # Compute the regularization matrix (lambda * I), excluding the bias term from regularization\n",
        "    I = np.eye(X_train.shape[1])\n",
        "    I[0, 0] = 0  # Do not regularize the bias term\n",
        "    \n",
        "    # Compute X^T * X\n",
        "    XtX = X_train.T @ X_train\n",
        "    \n",
        "    # Compute the inverse of (X^T * X + lambda * I)\n",
        "    XtX_lmbd_I_inv = np.linalg.inv(XtX + lmbd * I)\n",
        "    \n",
        "    # Compute X^T * y\n",
        "    Xty = X_train.T @ y_train\n",
        "    \n",
        "    # Compute the weight vector theta\n",
        "    theta = XtX_lmbd_I_inv @ Xty\n",
        "    \n",
        "    return theta\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzAAV9et1li5"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "Write the function *predict(X,theta)* which predicts housing values vector pred for a dataset X and a previously trained parameter vector $\\theta$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1k7w4Iyq1li6"
      },
      "outputs": [],
      "source": [
        "def predict(X, theta):\n",
        "    # Add bias term (column of ones) to X\n",
        "    X_augmented = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "    \n",
        "    # Compute the predictions\n",
        "    y_pred = X_augmented @ theta\n",
        "    \n",
        "    return y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H83oY9Zn1li6"
      },
      "source": [
        "### Exercise 4\n",
        "\n",
        "Write the function *mean_abs_loss(y_true,y_pred)* which computes the mean of the absolute differences between our prediction vector $y\\_pred$ and the real housing values $y\\_true$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hiNjDcM-1li7"
      },
      "outputs": [],
      "source": [
        "def mean_abs_loss(y_true, y_pred):\n",
        "    # Compute the absolute differences\n",
        "    absolute_differences = np.abs(y_true - y_pred)\n",
        "    \n",
        "    # Compute the mean of the absolute differences\n",
        "    mean_absolute_loss = np.mean(absolute_differences)\n",
        "    \n",
        "    return mean_absolute_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9CXkha41li7"
      },
      "source": [
        "### Exercise 5\n",
        "\n",
        "Evaluate your solutions by running the following code. \n",
        "\n",
        "Moreover, answer the following questions: What is the most important feature in your model? Are there features that are not so important? What happens if you remove them? Are there outliers with a high absolute loss?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "v-hRUKyC1li8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The mean absolute loss is 3428.558\n"
          ]
        }
      ],
      "source": [
        "seed = 3\n",
        "lmbd=1\n",
        "split=0.7\n",
        "X_train,y_train,X_test,y_test=split_train_test(X,y,split,seed)\n",
        "theta=train_linear_reg(X_train,y_train,lmbd)\n",
        "y_pred=predict(X_test,theta)\n",
        "mae=mean_abs_loss(y_test,y_pred)\n",
        "print ('The mean absolute loss is {loss:0.3f}'.format(loss=mae*1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Loss: 3.428557739962404\n",
            "             Feature  Coefficient\n",
            "0               Bias    32.535187\n",
            "1         crime_rate    -0.034069\n",
            "2     res_land_zoned     0.041596\n",
            "3           industry     0.017369\n",
            "4      charles_river     2.562492\n",
            "5                nox   -10.193440\n",
            "6      avg_num_rooms     3.832525\n",
            "7       prop_bf_1940    -0.009998\n",
            "8   dst_emply_center    -1.447981\n",
            "9     rd_highway_idx     0.281418\n",
            "10          tax_rate    -0.015609\n",
            "11  stdnt_tchr_ratio    -0.869075\n",
            "12       prop_blacks     0.011214\n",
            "13    low_status_pct    -0.576112\n",
            "Outliers with High Absolute Loss:\n",
            "     True Value  Predicted Value  Absolute Loss\n",
            "1           7.4         5.837220       1.562780\n",
            "2          19.0        13.020089       5.979911\n",
            "4          33.2        35.486706       2.286706\n",
            "5          16.5        10.052798       6.447202\n",
            "6          20.3        23.867555       3.567555\n",
            "..          ...              ...            ...\n",
            "145        12.7        11.678760       1.021240\n",
            "146        10.5        13.681365       3.181365\n",
            "148        26.2        24.246984       1.953016\n",
            "149        15.3        21.726219       6.426219\n",
            "150        20.8        18.619865       2.180135\n",
            "\n",
            "[117 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calculate mean absolute loss\n",
        "loss = mean_abs_loss(y_test, y_pred)\n",
        "print(\"Mean Absolute Loss:\", loss)\n",
        "\n",
        "# Analyze feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': ['Bias','crime_rate','res_land_zoned','industry','charles_river','nox','avg_num_rooms','prop_bf_1940','dst_emply_center','rd_highway_idx','tax_rate','stdnt_tchr_ratio','prop_blacks','low_status_pct'],\n",
        "    'Coefficient': theta\n",
        "})\n",
        "print(feature_importance)\n",
        "\n",
        "# Identify outliers with high absolute loss\n",
        "absolute_differences = np.abs(y_test - y_pred)\n",
        "outliers = pd.DataFrame({\n",
        "    'True Value': y_test,\n",
        "    'Predicted Value': y_pred,\n",
        "    'Absolute Loss': absolute_differences\n",
        "})\n",
        "outliers = outliers[outliers['Absolute Loss'] > 1]  # Threshold for high absolute loss\n",
        "print(\"Outliers with High Absolute Loss:\")\n",
        "print(outliers)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Lab07_LinearRegression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
